{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8a9247-327f-4dae-8620-7c2c0cfe4c9f",
   "metadata": {},
   "source": [
    "## 1. Scripts and IMDb Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bfdd6a-ae72-4675-a1c2-411921fe4a00",
   "metadata": {},
   "source": [
    "### Scripts and Sentiment Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d730c2fe-8eac-4590-bb8c-0f3885306300",
   "metadata": {},
   "source": [
    "Our ```scripts.csv``` dataset contains all lines of spoken dialogue across every Seinfeld episode, as well as their sentimental makeup. ```get_final_data.py``` uses ```load_data.py``` to load in all script data from [Kaggle](https://www.kaggle.com/thec03u5/seinfeld-chronicles). Raw data is then cleaned, reindexed, and reformatted to adhere to episode naming and numbering conventions adhered to by IMDb and Netflix naming conventions.\n",
    "\n",
    "*Refer to notes in ```load_data.py``` for in-depth notes on reindexing*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0261da-0566-45b6-b775-3baea97ebb19",
   "metadata": {},
   "source": [
    "Sentiment Analysis is then applied to extract the sentiment of each line of dialogue, using the ```text2emotion``` Python package in ```./scripts/precompute_tools/sentiment.py```. The emotional makeup of each line of dialogue is computed for each row in our data, ranging from 'Happy', 'Angry', 'Surprise', 'Sad', and 'Fear'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b247c-ad89-4386-95d8-6fddb8111aec",
   "metadata": {},
   "source": [
    "The final dialogue data, ```scripts```, is then stored as a ```.csv``` file in ```'./an_analysis_of_nothing/static/data'``` to be reformatted into a Pandas DataFrame with the following columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c10cb86-5296-485b-b648-6de21ed4a4d6",
   "metadata": {},
   "source": [
    "| Character   | Dialogue | SEID | Season | EpisodeNo | Happy | Angry | Surprise | Sad | Fear | numWords |\n",
    "| ----------- | -------- | ---- | ------ | --------- | ----- | ----- | -------- | --- | ---- | -------- |\n",
    "| JERRY | 'Yes, it was purple..' | S01E01 | 1 | 1 | .24 | 0 | 0 | .41 | .35 | 189 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7651e-8e02-40d3-ba74-8f93ea7a697c",
   "metadata": {},
   "source": [
    " ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09bc57f-ec08-4df2-96f0-8bed5b74568e",
   "metadata": {},
   "source": [
    "### IMDb Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48248bd1-a80f-4fc1-985e-c756113eb37c",
   "metadata": {},
   "source": [
    "Our ```metadata.csv``` dataset contains basic and advances metadata for each episode of Seinfeld. Basic IMDb metadata is parsed and cleaned by ```load_data.py``` from [IMDb Interfaces](https://www.imdb.com/interfaces/). We then call ```_scrape_epi_pages.py``` and use the Python ```requests``` to scrape episode descriptions, user-generated plot summaries, and user-generated plot keywords from the IMDb pages of each episode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a835d-b75b-4115-bad6-a573e5d1527f",
   "metadata": {},
   "source": [
    "The final dialogue data, ```meta```, is then stored as a ```.csv``` file in ```'./an_analysis_of_nothing/static/data'``` to be reformatted into a Pandas DataFrame with the following columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f9537-abe4-40a5-aeb5-3a73426f1699",
   "metadata": {},
   "source": [
    "|Season|EpisodeNo|AirDate |Writers                    |Director |SEID  |tconst   |Title              |EpiNo_Netflix|runtimeMinutes|numVotes|averageRating|Description                                                                                               |Summaries                                                                                                                                                                                                                                                                                                                                                                      |keyWords                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
    "|------|---------|--------|---------------------------|---------|------|---------|-------------------|-------------|--------------|--------|-------------|----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "|1     |1        |5-Jul-89|Larry David, Jerry Seinfeld|Art Wolff|S01E01|tt0098286|Good News, Bad News|1            |23            |6031    |7.4          |'Jerry and George argue... '|['In this episode, ...']|['tv series pilot', 'cafe', 'waitress', ..]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48c86b4-6cde-4f1c-a3b4-b42153e515cb",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e52b9e4-2bd1-4734-a5b2-36d356136099",
   "metadata": {},
   "source": [
    "## 2. Search Query Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ccdd1-cfd1-432e-b072-ecbffd1c0f92",
   "metadata": {},
   "source": [
    "Additional numpy vectors for episode querying are also generated using ```get_final_data.py```, which calls  ```create_corpus_embeddings``` in ```./scripts/precompute_tools/query_vectors.py``` to use a Sentence Transformer model to generate dialogue embeddings, and store sharded files as numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8b0790-6bf2-4ccc-b3bd-895aab0327f3",
   "metadata": {},
   "source": [
    "These dialogue feature vectors were called in advance to allow for fast querying without the need to re-encode every line of dialogue upon each new search query input. The result is a 54590x384 torch tensor stored as 10 .NPY files, located in ```./an_analysis_of_nothing/static/data/dialogue_tensors```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
